\documentclass{beamer}
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{footline}
{
    \leavevmode%
    \hbox{%
    \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.05\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
        \insertframenumber{}
    \end{beamercolorbox}}%
    \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\renewcommand{\familydefault}{\sfdefault}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{parse-numbers=false}

\setlength{\OuterFrameSep}{-2pt}
\makeatletter
\preto{\@verbatim}{\topsep=-10pt \partopsep=-10pt }
\makeatother

\title[Lecture 10:\ Nonlinear Least Squares II]{Lecture 10:\ Nonlinear Least Squares II}
\author[ResEcon 703:\ Advanced Econometrics]{ResEcon 703:\ Topics in Advanced Econometrics}
\date{Matt Woerman\\University of Massachusetts Amherst}

\begin{document}
<<include = FALSE>>=
library(knitr)
opts_chunk$set(size = 'footnotesize')
options(width = 70)
@

{\setbeamertemplate{footline}{} 
\begin{frame}[noframenumbering]
    \titlepage
\end{frame}
}

\begin{frame}\frametitle{Agenda}
    Last time
    \begin{itemize}
        \item Nonlinear Least Squares
    \end{itemize}
    \vspace{2ex}
    Today
    \begin{itemize}
        \item Nonlinear Least Squares Example in R
    \end{itemize}
    \vspace{2ex}
    Upcoming
    \begin{itemize}
        \item Reading for next time
        \begin{itemize}
            \item Greene textbook, Chapters 13.1--13.5
        \end{itemize}
        \item Problem sets
        \begin{itemize}
            \item Problem Set 2 is posted, due October 17
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Nonlinear Least Squares}
    $$y_i = h(x_i, \beta) + \varepsilon_i$$ \\
    \vspace{2ex}
    The nonlinear lest squares estimator minimizes the sum of squared errors for this model
    $$\hat{\beta} = \argmin_{\beta} \sum_{i = 1}^n [y_i - h(x_i, \beta)]^2$$ \\
    \vspace{2ex}
    This estimator does not require a distributional assumption about our data (unlike MLE), but it has fewer nice properties
    \begin{itemize}
        \item Consistent
        \item Asymptotically normal
        \item Does not achieve the Cramer-Rao lower bound
        \item Does not have the ``invariance'' property
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Nonlinear Least Squares Example in R
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Multinomial Logit Estimation Example}
    We are again studying how consumers make choices about expensive and highly energy-consuming systems in their homes. We have data on 900 households in California and the type of heating system in their home. Each household has the following choice set, and we observe the following data \\
    \vspace{3ex}
    \begin{columns}
    	\begin{column}{0.5\textwidth}
		    Choice set
		    \begin{itemize}
		    	\item GC: gas central
		    	\item GR: gas room
		    	\item EC: electric central
		    	\item ER: electric room
		    	\item HP: heat pump
		    \end{itemize}
		    \vspace{8ex}
	    \end{column}
	    \begin{column}{0.5\textwidth}
		    Alternative-specific data
		    \begin{itemize}
		    	\item IC: installation cost
		    	\item OC: annual operating cost
		    \end{itemize}
		    \vspace{2ex}
		    Household demographic data
		    \begin{itemize}
		    	\item income: annual income
		    	\item agehed: age of household head
		    	\item rooms: number of rooms
                \item region: home location
		    \end{itemize}
		\end{column}
    \end{columns}
\end{frame}

\begin{frame}[fragile]\frametitle{Load Dataset}
    <<message = FALSE>>=
    ### Load and look at dataset
    ## Load tidyverse and mlogit
    library(tidyverse)
    library(mlogit)
    ## Load dataset from mlogit package
    data('Heating', package = 'mlogit')
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Dataset}
    <<>>=
    ## Look at dataset
    as_tibble(Heating)
    @
\end{frame}

\begin{frame}\frametitle{Two Models to Estimate}
    \vspace{-4ex}
    \begin{align*}
        \intertext{Base model}
        U_{nj} &= \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \varepsilon_{nj} \\
        \vspace{3ex}
        \intertext{Alternative-specific coefficients model}
        U_{nj} &= \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \beta_{3j} R_n + \varepsilon_{nj}
    \end{align*}
\end{frame}

\begin{frame}[fragile]\frametitle{Optimization in R}
    <<eval = FALSE>>=
    ### Optimization in R
    ## Help file for the optimization function, optim
    ?optim
    ## Arguments for optim function
    optim(par, fn, gr, ..., method, lower, upper, control, hessian)
    @
    \vspace{2ex}
    \texttt{optim()} requires that you create a function, \texttt{fn}, that
    \begin{enumerate}
        \item Takes a set of parameters and data as inputs
        \item Calculates your objective function given those parameters
        \item Returns this value of the objective function
    \end{enumerate}
    \vspace{2ex}
    You also have to give \texttt{optim()} arguments for
    \begin{itemize}
        \item \texttt{par}: starting parameter values
        \item \texttt{\ldots}: dataset and other things needed by your function
        \item \texttt{method}: optimization algorithm
        \begin{itemize}
            \item I recommend \texttt{method = 'BFGS'} for our estimation
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Calculating the Sum of Squared Error in a Logit Model}
    Steps to calculate the sum of squared errors for a given set of parameters in a logit model
    \begin{enumerate}
        \item Calculate the representative utility for each alternative and for each decision maker.
        \item Calculate the choice probability of driving for each decision maker.
        \item Calculate the econometric residual, or the difference between the outcome and the probability, for each decision maker.
        \item Sum the square of these residuals.
        \item Return the sum of squares.
    \end{enumerate}
\end{frame}

\begin{frame}\frametitle{Base Model}
    \begin{alignat*}{2}
    &\text{Random utility model:} \quad &&U_{nj} = \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \varepsilon_{nj} \\
    \intertext{}
    &\text{NLS regression model:} \quad &&y_{ni} =  \frac{e^{\alpha_i + \beta_1 IC_{ni} + \beta_2 OC_{ni}}}{\sum_{j = 1}^J e^{\alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj}}} + \omega_{ni}
    \end{alignat*}
\end{frame}

\begin{frame}[fragile]\frametitle{Function to Calculate Sum of Squares}
    \vspace{1ex}
    <<size = 'tiny'>>=
    ### Calculate NLS estimator for multinomial logit heating choice using cost data 
    ### and alternative effects
    ## Function to calculate sum of squares using two variables and four 
    ## alternative effects
    least_squares_long <- function(parameters, data){
      ## Extract individual parameters
      alphas <- parameters[1:4]
      beta_1 <- parameters[5]
      beta_2 <- parameters[6]
      ## Assign constant parameters to alternatives
      data <- data %>% 
        group_by(idcase) %>% 
        arrange(idcase, alt) %>% 
        mutate(constant = c(alphas, 0)) %>% 
        ungroup()
      ## Calculate utility for each alternative given the parameters
      data <- data %>% 
        mutate(utility = constant + beta_1 * var_1 + beta_2 * var_2)
      ## Calculate logit probability denominator given the parameters
      data <- data %>% 
        group_by(idcase) %>% 
        mutate(probability_denominator = sum(exp(utility))) %>% 
        ungroup()
      ## Calculate logit choice probability given the parameters
      data <- data %>%
        mutate(probability = exp(utility) / probability_denominator)
      ## Calculate regression residual given the parameters
      data <- data %>%
        mutate(residual = choice - probability)
      ## Calculate the sum of squares given the parameters
      sum_squares <- sum(data$residual^2)
      return(sum_squares)
    }
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Estimate NLS Parameters}
    <<>>=
    ## Gather heating dataset into a long dataset
    heating_long <- Heating %>% 
      gather(key, value, starts_with('ic.'), starts_with('oc.')) %>% 
      separate(key, c('cost', 'alt')) %>% 
      spread(cost, value) %>% 
      mutate(choice = (depvar == alt)) %>% 
      select(-depvar) %>% 
      mutate(var_1 = ic, var_2 = oc)
    ## Minimize the sum of squared errors
    model_nls_long <- optim(rep(0, 6), least_squares_long, 
                            data = heating_long, method = 'BFGS')
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Estimation Results}
    <<>>=
    ## Show NLS estimation results
    model_nls_long
    @
\end{frame}

\begin{frame}\frametitle{NLS Variance-Covariance Matrix Estimator}
    $$\widehat{Var}(\hat{\beta}) = \hat{\sigma}^2 \left[ \sum_{i = 1}^n \left( \frac{\partial h(x_i, \beta)}{\partial \beta} \right)_{\hat{\beta}} \left( \frac{\partial h(x_i, \beta)}{\partial \beta'} \right)_{\hat{\beta}} \right]^{-1}$$
    Steps to estimate this variance-covariance matrix
    \begin{enumerate}
        \item Write down the derivative of the nonlinear regression model with respect to each of the $K$ parameters.
        \item Calculate this $K \times 1$ vector of derivatives, at the estimated parameters, for each decision maker.
        \item Calculate the $K \times K$ matrix that is the product of the above vector and its transpose for each decision maker.
        \item Sum these matrices for all decision makers.
        \item Estimate the variance of the econometric error as the mean sum of squares at the estimated parameters.
        \item Calculate the variance-covariance matrix, which is a function of the above $K \times K$ matrix and the estimated error variance.
    \end{enumerate}
\end{frame}

\begin{frame}\frametitle{Gradient of Logit Choice Probabilities}
    \begin{align*}
        \frac{\partial P_{ni}}{\partial \alpha_i} &= P_{ni} (1 - P_{ni}) \\
        \frac{\partial P_{ni}}{\partial \alpha_{j \mid j \neq i}} &= -P_{ni} P_{nj} \\
        \frac{\partial P_{ni}}{\partial \beta_1} &= P_{ni} (IC_{ni} - \sum_{j= 1}^J P_{nj} IC_{nj}) \\
        \frac{\partial P_{ni}}{\partial \beta_2} &= P_{ni} (OC_{ni} - \sum_{j= 1}^J P_{nj} OC_{nj})
    \end{align*}
\end{frame}

\begin{frame}[fragile]\frametitle{Estimating the NLS Variance-Covariance Matrix}
    <<size = 'tiny'>>=
    ### Estimate the variance of the previous NLS model
    ## Assign constant parameters to alternatives
    variance_data <- heating_long %>% 
      group_by(idcase) %>% 
      arrange(idcase, alt) %>% 
      mutate(constant = c(model_nls_long$par[1:4], 0)) %>% 
      ungroup()
    ## Calculate utility for each alternative at the NLS parameters
    variance_data <- variance_data %>% 
      mutate(utility = constant + 
               model_nls_long$par[5] * var_1 + model_nls_long$par[6] * var_2)
    ## Calculate logit probability denominator at the NLS parameters
    variance_data <- variance_data %>% 
      group_by(idcase) %>% 
      mutate(probability_denominator = sum(exp(utility))) %>% 
      ungroup()
    ## Calculate logit choice probability at the NLS parameters
    variance_data <- variance_data %>%
      mutate(probability = exp(utility) / probability_denominator)
    ## Create vectors of individual probabilities
    variance_data <- variance_data %>% 
      select(idcase, alt, probability) %>% 
      spread(alt, probability) %>% 
      mutate(probability_all = pmap(list(.$ec, .$er, .$gc, .$er), 
                                    ~ c(..1, ..2, ..3, ..4))) %>% 
      select(idcase, probability_all) %>% 
      full_join(variance_data, by = 'idcase')
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Estimating the NLS Variance-Covariance Matrix}
    <<size = 'tiny'>>=
    ## Calculate the probability-weighted average of each cost for each individual
    variance_data <- variance_data %>% 
      group_by(idcase) %>% 
      mutate(ic_weighted = sum(probability * ic),
             oc_weighted = sum(probability * oc)) %>% 
      ungroup()
    ## Calculate the gradient for each alternative and individual
    variance_data <- variance_data %>% 
      group_by(idcase) %>% 
      arrange(idcase, alt) %>% 
      mutate(alt_order = 1:n()) %>% 
      ungroup() %>% 
      mutate(constant_vector = map(.$alt_order, ~ c(rep(0, .x - 1), 
                                                    1, 
                                                    rep(0, 5 - .x))[1:4])) %>% 
      mutate(gradient_alpha = pmap(list(.$probability, 
                                        .$probability_all, 
                                        .$constant_vector), 
                                   ~ ..1 * (..3 - ..2))) %>% 
      mutate(gradient = pmap(list(.$gradient_alpha, .$probability, 
                                  .$ic, .$ic_weighted, .$oc, .$oc_weighted),
                             ~ c(..1, 
                                 ..2 * (..3 - ..4),
                                 ..2 * (..5 - ..6))))
    ## Calculate the gradient product matrix for each alternative and individual
    variance_data <- variance_data %>% 
      mutate(gradient_matrix = map(.$gradient, ~ .x %*% t(.x)))
    ## Sum the gradient product matrices over all alternatives and individuals
    gradient_matrix_sum <- variance_data$gradient_matrix %>% reduce(`+`)
    ## Estimate the variance of the econometric errors
    error_variance <- least_squares_long(model_nls_long$par, heating_long) /
      nrow(heating_long)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{NLS Variance-Covariance Matrix}
    <<>>=
    ## Calculate the variance-covariance matrix
    variance_covariance <- error_variance * solve(gradient_matrix_sum)
    variance_covariance
    @
\end{frame}

\begin{frame}[fragile]\frametitle{NLS Parameters and Standard Errors}
    <<>>=
    ## Report estimated parameters and standard errors
    model_nls_long$par
    variance_covariance %>% 
      diag() %>% 
      sqrt()
    @
\end{frame}

\begin{frame}\frametitle{NLS Hypothesis Test}
    Test that the alternative-specific intercepts are jointly significant
    $$H_0:
    \begin{pmatrix}
        \alpha_1 \\
        \alpha_2 \\
        \alpha_3 \\
        \alpha_4
    \end{pmatrix}
    =
    \begin{pmatrix}
        0 \\
        0 \\
        0 \\
        0
    \end{pmatrix}$$
\end{frame}

\begin{frame}\frametitle{NLS Wald Test}
    \begin{alignat*}{2}
        &\text{Hypothesis:} &&H_0 \text{: } r(\beta_0) = q \\
        &\text{Test statistic:} &&W = [r(\hat{\beta}) - q]' [ R(\hat{\beta}) \widehat{Var}(\hat{\beta}) R'(\hat{\beta})]^{-1} [r(\hat{\beta}) - q] \\
        &\text{Jacobian matrix:} \quad &&R(\hat{\beta}) = \left( \frac{\partial r(\beta)}{\partial \beta'} \right)_{\hat{\beta}}
    \end{alignat*} \\
    \vspace{2ex}
    Steps to conduct a Wald Test using NLS estimators
    \begin{enumerate}
        \item Create a vector of $J$ parameter restrictions, $r(\beta_0) = q$.
        \item Calculate the $J \times K$ Jacobian matrix by differentiating each restriction with respect to each of the $K$ parameters.
        \item Calculate the Wald test statistic, which is a function of the vector of restrictions, the Jacobian matrix, and the variance-covariance matrix.
        \item Conduct the Wald test using this test statistic, which is distributed $\chi^2$.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]\frametitle{Calculating the NLS Wald Test Statistic}
    <<>>=
    ### Conduct a Wald test that alternative-specific intercepts equal zero
    ## Calculate the restriction vector
    restriction_vector <- model_nls_long$par[1:4]
    ## Construct the restriction Jacobian
    restriction_jacobian <- diag(4) %>% 
      cbind(rep(0, 4)) %>% 
      cbind(rep(0, 4))
    ## Calculate the Wald test statistic
    wald_test_stat <- t(restriction_vector) %*% 
      solve(restriction_jacobian %*% 
              variance_covariance %*% 
              t(restriction_jacobian)) %*% 
      restriction_vector %>% 
      c()
    @
\end{frame}

\begin{frame}[fragile]\frametitle{NLS Wald Test Results}
    <<>>=
    ## Test if Wald test statitsic is greater than critical value
    wald_test_stat > qchisq(0.95, 4)
    ## Calculate p-value of Wald test
    1 - pchisq(wald_test_stat, 4)
    @
\end{frame}

\begin{frame}\frametitle{Alternative-Specific Coefficients Model}
    \begin{alignat*}{2}
    &\text{Random utility model:} \quad &&U_{nj} = \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \beta_{3j} R_n + \varepsilon_{nj} \\
    \intertext{}
    &\text{NLS regression model:} \quad &&y_{ni} =  \frac{e^{ \alpha_i + \beta_1 IC_{ni} + \beta_2 OC_{ni} + \beta_{3j} R_n}}{\sum_{j = 1}^J e^{ \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \beta_{3j} R_n}} + \omega_{ni}
    \end{alignat*}
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients Estimation}
    <<size = 'tiny'>>=
    ### Calculate NLS estimator for multinomial logit heating choice using cost 
    ### data, alternative effects, and alternative-specific coefficients on rooms
    ## Function to calculate sum of squares using flexible matrices
    least_squares_matrix <- function(parameters, data){
      ## Extract explanatory variables
      data_x <- data %>% 
        map(1)
      ## Extract choice data
      data_y <- data %>% 
        map(2)
      ## Calculate utility for each alternative given the parameters
      utility <- data_x %>% 
        map(~ .x %*% parameters)
      ## Calculate logit probability denominator given the parameters
      probability_denominator <- utility %>% 
        map(~ sum(exp(.x)))
      ## Calculate logit probability numerator given the parameters
      probability_numerator <- utility %>% 
        map(~ exp(.x))
      ## Calculate logit choice probability given the parameters
      probability_choice <- probability_numerator %>% 
        map2(probability_denominator, ~ .x / .y)
      ## Calculate square residual given the parameters
      residuals <- data_y %>% 
        map2(probability_choice, ~ .x - .y)
      ## Calculate the sum of squares given the parameters
      sum_squares <- residuals %>%
        map(~ sum(.x^2)) %>% 
        unlist() %>% 
        sum()
      return(sum_squares)
    }
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients Estimation Data}
    <<size = 'tiny'>>=
    ## Split heating dataset into list of household data frames
    heating_split <- heating_long %>% 
      group_by(idcase) %>% 
      arrange(idcase, alt) %>% 
      group_split()
    ## Crate matrix of dummy variables (intercepts) to bind to data
    constant_matrix <- diag(4) %>% 
      rbind(c(0, 0, 0, 0))
    ## Function to create list of datasets for estimation
    create_data_matrix <- function(data){
      data_x <- data %>% 
        select(ic, oc) %>% 
        as.matrix()
      data_x <- constant_matrix %>% 
        cbind(data_x)
      rooms <- data$rooms[1]
      data_x <- 
        data_x %>% 
        cbind(rooms * constant_matrix)
      data_y <- data %>% 
        select(choice) %>% 
        mutate(choice = 1 * choice) %>% 
        pull(choice)
      return(list(x = data_x, y = data_y))
    }
    ## Create list of datasets for estimation
    heating_matrix <- heating_split %>% 
      map(.x = ., .f = ~ create_data_matrix(.x))
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients Optimization}
    <<>>=
    ## Minimize the sum of square errors
    model_matrix <- optim(rep(0, 10), least_squares_matrix, 
                          data = heating_matrix, method = 'BFGS')
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients NLS Results}
    <<>>=
    ## Show NLS parameters
    model_matrix$par
    @
\end{frame}

\begin{frame}\frametitle{Announcements}
    Reading for next time
    \begin{itemize}
        \item Greene textbook, Chapters 13.1--13.5
    \end{itemize}
    \vspace{3ex}
    Office hours
    \begin{itemize}
        \item Reminder: Tuesdays at 2:00--3:00 in 218 Stockbridge
    \end{itemize}
    \vspace{3ex}
    Upcoming
    \begin{itemize}
        \item Problem Set 2 is posted, due October 17
    \end{itemize}
\end{frame}

\end{document}
