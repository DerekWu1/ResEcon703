\documentclass{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{footline}
{
    \leavevmode%
    \hbox{%
    \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.05\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
        \insertframenumber{}
    \end{beamercolorbox}}%
    \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{parse-numbers=false}

\setlength{\OuterFrameSep}{-2pt}
\makeatletter
\preto{\@verbatim}{\topsep=-10pt \partopsep=-10pt }
\makeatother

\title[Lecture 3:\ Random Utility Model]{Lecture 3:\ Random Utility Model}
\author[ResEcon 703:\ Advanced Econometrics]{ResEcon 703:\ Topics in Advanced Econometrics}
\date{Matt Woerman\\University of Massachusetts Amherst}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


{\setbeamertemplate{footline}{} 
\begin{frame}[noframenumbering]
    \titlepage
\end{frame}
}

\begin{frame}\frametitle{Agenda}
    Last time
    \begin{itemize}
        \item R tutorial
    \end{itemize}
    \vspace{2ex}
    Today
    \begin{itemize}
    	\item Discrete Choice
        \item Random Utility Model
        \item Linear Probability Model
        \item Linear Probability Model Example in R
    \end{itemize}
    \vspace{2ex}
    Upcoming
    \begin{itemize}
        \item Reading for next time
        \begin{itemize}
            \item Train textbook, Chapters 3.1--3.6
            \item Gruber and Proterba (1994)
        \end{itemize}
        \item Problem set
        \begin{itemize}
            \item Problem Set 1 is posted, due September 24
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Discrete Choice
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Discrete Choice}
    Many problems in microeconomics and related fields involve a decision maker choosing between a discrete set of alternatives
    \begin{itemize}
    	\item Whether a self-employed person buys health insurance
    	\item Which lake or river an angler visits to fish
    	\item Which city a household chooses to locate in
    	\item Which phone plan a household purchases and when they make calls
    	\item Which appliances a household purchases
    	\item Which health insurance plan an employee chooses
    	\item What pollution control equipment a power plant installs
    	\item Whether and when a city chooses to replace bus engines
    	\item Which automobile a household purchases
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Analyzing a Discrete Choice Problem}
    Three steps to set up and analyze a discrete choice problem
    \begin{enumerate}
    	\item Specify the choice set
    	\item Formulate a model of how the agent chooses among the choice set
    	\item Estimate the unknown parameters on the model
    \end{enumerate}
\end{frame}

\begin{frame}\frametitle{Choice Set}
    The choice set defines all of the possible alternatives available to the decision maker
    \begin{itemize}
    	\item Example: How to get to campus?
    	\begin{itemize}
    		\item Drive alone, carpool, bus, bike, walk, Uber, stay home, etc.
    	\end{itemize}
    \end{itemize}
    \vspace{2ex}
    Alternatives must be mutually exclusive and exhaustive
    \begin{itemize}
    	\item Mutually exclusive: The agent may choose only one alternative, and choosing that alternative precludes choosing any other alternative
    	\item Exhaustive: That agent must chooses one of the alternatives, so all possible alternatives must be included
    \end{itemize}
    \vspace{2ex}
    The choice set will depend on the context, research question, data availability, etc.
\end{frame}

\begin{frame}\frametitle{Discrete Choice Model and Estimation}
    Step 2: Formulate a model of how the agent chooses among the choice set \\
    \begin{itemize}
    	\item Random utility model: coming up next
    \end{itemize}
    \vspace{3ex}
    Step 3: Estimate the unknown parameters on the model
    \begin{itemize}
    	\item Estimation methods: the rest of the semester
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Random Utility Model
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Random Utility Model}
    Discrete choices are usually modeled under the assumption of utility-maximizing behavior by the decision maker (or profit maximization when the decision maker is a firm) \\
    \vspace{2ex} 
    The random utility model (RUM) provides such a framework
    \begin{itemize}
    	\item The agent gets some amount of utility from each of the alternatives
    	\begin{itemize}
    		\item The amount of utility can depend on observed characteristics of the alternatives, observed characteristics of the decision maker, and unobserved characteristics
    	\end{itemize}
    	\item The agent selects the alternative that provides the greatest utility
    \end{itemize}
    \vspace{2ex}
    Models derived from RUM are consistent with utility (or profit) maximization, even if the decision maker does not maximize utility
    \begin{itemize}
    	\item RUMs can be highly flexible and include behavioral and information parameters that diverge from the traditional neoclassical model
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Specifying a Random Utility Model}
	The model from the perspective of the decision maker
	\begin{itemize}
		\item A decision maker, $n$, faces a choice among $J$ alternatives
    	\item Alternative $j$ provides utility $U_{nj}$ (where $j = 1, \ldots, J$)
    	\item The decision maker chooses the alternative with the greatest utility
    	\begin{itemize}
    		\item $n$ chooses $i$ if and only if $U_{ni} > U_{nj} \; \forall j \neq i$
    	\end{itemize}
   	\end{itemize}
   	\vspace{3ex}
   	But we (the econometricians) do not observe $U_{nj}$!
   	\begin{itemize}
   		\item We observe
   		\begin{itemize}
   			\item The choice
   			\item Some attributes of each alternative
   			\item Some attributes of the decision maker
   		\end{itemize}
   		\item We will use these data to infer $U_{nj}$
   	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Utility Decomposition}
	Decompose the utility of each alternative, $U_{nj}$, into two components
	\begin{itemize}
		\item Observed factors: $V_{nj}$
		\item Unobserved factors: $\varepsilon_{nj}$
	\end{itemize}
	$$U_{nj} = V_{nj} + \varepsilon_{nj}$$ \\
	\vspace{2ex}
	$V_{nj} = V(x_{nj}, s_n)$ is called representative utility
	\begin{itemize}
		\item $x_{nj}$: Attributes of the alternatives
		\item $s_n$: Attributes of the decision maker
		\item Also depends on parameters, but we will get to those later
	\end{itemize}
	\vspace{2ex}
	$\varepsilon_{nj}$ is everything that affects utility not included in $V_{nj}$
	\begin{itemize}
		\item Depends importantly on the specification of $V_{nj}$
		\item Unobserved, so we treat this term as random
		\item $f(\varepsilon_n)$ is the joint density of the random vector $\varepsilon_n = \{\varepsilon_{n1}, \dots, \varepsilon_{nJ}\}$ for decision maker $n$
	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Choice Probabilities}
    $U_{nj}$ contains a random components, so we cannot say for certain which alternative the decision maker will choose
    \begin{itemize}
    	\item But we can form probabilities!
    \end{itemize}
    \vspace{1ex}
    The probability the decision maker chooses alternative $i$ is
    \begin{align*}
    	P_{ni} &= \Pr(U_{ni} > U_{nj} \; \forall j \neq i) \\
    	&= \Pr(V_{ni} + \varepsilon_{ni} > V_{nj} + \varepsilon_{nj} \; \forall j \neq i) \\
    	&= \Pr(\varepsilon_{nj} - \varepsilon_{ni} < V_{ni} - V_{nj} \; \forall j \neq i) \\
    	&= \int_\varepsilon I(\varepsilon_{nj} - \varepsilon_{ni} < V_{ni} - V_{nj} \; \forall j \neq i) f(\varepsilon_n) d\varepsilon_n
    \end{align*} \\
    \vspace{1ex}
    This probability is the cumulative distribution of $\varepsilon_{nj} - \varepsilon_{ni}$
    \begin{itemize}
    	\item Multidimensional integral over the density of the unobserved component of utility, $f(\varepsilon_n)$
    	\item Assumptions about $f(\varepsilon_n)$ yield different discrete choice models
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Choice Probabilities Example}
    A person chooses whether to take a car ($c$) or a bus ($b$) to work
    \begin{itemize}
    	\item We observe the time, $T$, and cost, $M$, of each choice
    \end{itemize}
    \vspace{1ex}
    We specify the representative utility of each alternative as
    \begin{align*}
    	V_c &= \alpha T_c + \beta M_c \\
    	V_b &= \alpha T_b + \beta M_b
    \end{align*}
    Suppose $\alpha$ and $\beta$ are known (we will talk about estimating them later)
    \begin{itemize}
    	\item Then $V_c$ and $V_b$ are known, so we know which has greater representative utility
    	\item But unobserved factors also affect this decision: $\varepsilon_c$ and $\varepsilon_b$
    \end{itemize}
    \vspace{2ex}
    The probability of each choice is
    \begin{align*}
    	P_c &= \Pr(\varepsilon_b - \varepsilon_c < V_c - V_b) \\
    	P_b &= \Pr(\varepsilon_c - \varepsilon_b < V_b - V_c)
    \end{align*}
\end{frame}

\begin{frame}\frametitle{Properties of the Random Utility Model}
    The random utility model implies two important properties about discrete choice models
    \begin{itemize}
    	\item Only difference in utility matter
    	\begin{itemize}
    		\item We ultimately do not care about the level of utility from any alternative, just the comparisons between any two alternatives
    		\item We can only estimate parameters that capture differences between alternatives
    	\end{itemize}
    	\item The scale of utility is arbitrary
    	\begin{itemize}
    		\item Scaling all utilities does not change the comparison between alternatives
    		\item We will usually normalize the variance of the error terms 
    	\end{itemize}
    \end{itemize}
    \vspace{3ex}
    We will talk about these properties more when we talk about estimation
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Linear Probability Model
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Binary Choice}
    The discrete choice problem is greatly simplified with only two alternatives
    \begin{itemize}
    	\item With only two alternatives, there is only one comparison to model
    \end{itemize}
    \vspace{2ex}
    The choice probabilities can be fully described with only one modeling equation 
    $$P_{n1} = \Pr(\varepsilon_{n2} - \varepsilon_{n1} < V_{n1} - V_{n2})$$
    \begin{itemize}
    	\item If the choice set is mutually exclusive and exhaustive, then it must be the case that $P_{n2} = 1 - P_{n1}$
    \end{itemize}
    \vspace{2ex}
    We will typically assume representative utility is linear: $V_{ni} = \beta' x_{ni}$
    $$P_{n1} = \Pr(\varepsilon_{n2} - \varepsilon_{n1} < \beta' (x_{n1} - x_{n2}))$$
\end{frame}

\begin{frame}\frametitle{Linear Probability Model}
    Let's abstract from the structural model and consider a non-structural approach to estimate a binary choice model
    \begin{itemize}
    	\item From the structural model, the choice is a function of $x_n = \{x_{n1}, x_{n2}\}$
    \end{itemize}
    \vspace{2ex}
    A simple regression to estimate this relationship is
    $$Y_n = \alpha' x_n + \omega_n$$
    where
    \begin{itemize}
    	\item $Y_n = 1$ if and only if $n$ chooses alternative $1$
    \end{itemize}
    \vspace{2ex}
    Under standard OLS assumptions
    $$\Pr(Y_n = 1 \mid x_n) = E(Y_n \mid x_n) = \alpha' x_n$$
    So this is called the linear probability model (LPM)
\end{frame}

\begin{frame}\frametitle{Pros and Cons of the Linear Probability Model}
    Pros
    \begin{itemize}
    	\item You can estimate the LMP using OLS
    	\begin{itemize}
    		\item Regression is fast and easy to run
    		\item Assumptions are transparent and well-known
    	\end{itemize}
    	\item Coefficients can be interpreted as marginal effects
    \end{itemize}
    \vspace{3ex}
    Cons
    \begin{itemize}
    	\item Probabilities are not bounded by $[0, 1]$
    	\begin{itemize}
    		\item Coefficients can be biased and inconsistent
    	\end{itemize}
    	\item Coefficients are not structural parameters
    	\item Error terms are heteroskedastic and not normally distributed
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Linear Probability Model Example in R
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Linear Probability Model Example}
    We are studying how consumers make choices about expensive and highly energy-consuming appliances in their homes. We have data on 600 households who rent a studio apartment and whether or not they choose to purchase a window air conditioning unit. For each household, we observe the purchase price of the air conditioner and its annual operating cost. (To simplify things, we assume there is only one ``representative'' air conditioner for each household and how much the household operates the air conditioner is fixed.) We can use a linear probability model to see how the purchase price and the operating cost affect the decision to purchase.
    $$Y_n = \beta_0 + \beta_1 P_n + \beta_2 C_n + \omega_n$$
    where
    \begin{itemize}
    	\item $Y_n = 1$ if and only if $n$ purchases an air conditioner
    	\item $P_n$ is the purchase price of the air conditioner
    	\item $C_n$ is the annual operating cost of the air conditioner
    \end{itemize}
\end{frame}

\begin{frame}[fragile]\frametitle{Load Dataset}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Load and look at dataset}
\hlcom{## Load tidyverse}
\hlkwd{library}\hlstd{(tidyverse)}
\end{alltt}
\end{kframe}
\end{knitrout}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Load dataset}
\hlstd{data} \hlkwb{<-} \hlkwd{read_csv}\hlstd{(}\hlstr{'ac_renters.csv'}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Parsed with column specification:\\\#\# cols(\\\#\#\ \  air\_conditioning = col\_logical(),\\\#\#\ \  cost\_system = col\_double(),\\\#\#\ \  cost\_operating = col\_double(),\\\#\#\ \  income = col\_double(),\\\#\#\ \  residents = col\_double(),\\\#\#\ \  city = col\_double()\\\#\# )}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Dataset}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Look at dataset}
\hlstd{data}
\end{alltt}
\begin{verbatim}
## # A tibble: 600 x 6
##    air_conditioning cost_system cost_operating income residents  city
##    <lgl>                  <dbl>          <dbl>  <dbl>     <dbl> <dbl>
##  1 FALSE                    620            258     74         1     1
##  2 FALSE                    685            141     74         1     1
##  3 FALSE                    570            152     57         1     1
##  4 TRUE                     497            193     81         1     1
##  5 TRUE                     541            162     59         2     1
##  6 FALSE                    663            160     50         2     1
##  7 FALSE                    579            185     60         1     1
##  8 FALSE                    502            158     61         1     1
##  9 TRUE                     562            132     48         3     1
## 10 FALSE                    495            111     44         1     1
## # ... with 590 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Linear Probability Model Regression}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Model air conditioning as a linear probability model}
\hlcom{## Regress air conditioning on cost variables}
\hlstd{reg_lmp} \hlkwb{<-} \hlstd{data} \hlopt{%>%}
  \hlkwd{lm}\hlstd{(}\hlkwc{formula} \hlstd{= air_conditioning} \hlopt{~} \hlstd{cost_system} \hlopt{+} \hlstd{cost_operating)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Regression Summary}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Summarize regression results}
\hlstd{reg_lmp} \hlopt{%>%}
  \hlkwd{summary}\hlstd{()}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = air_conditioning ~ cost_system + cost_operating, 
##     data = .)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7926 -0.5013  0.2716  0.4314  0.7961 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     1.6745533  0.2120082   7.899 1.36e-14 ***
## cost_system    -0.0012918  0.0003402  -3.797 0.000161 ***
## cost_operating -0.0023549  0.0004857  -4.849 1.59e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4832 on 597 degrees of freedom
## Multiple R-squared:  0.06324,	Adjusted R-squared:  0.0601 
## F-statistic: 20.15 on 2 and 597 DF,  p-value: 3.394e-09
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Visualize Choice Probability}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Visualize probability of air conditioning adoption}
\hlcom{## Calculate probability of air conditioining}
\hlstd{data} \hlkwb{<-} \hlstd{data} \hlopt{%>%}
  \hlkwd{mutate}\hlstd{(}\hlkwc{probability_ac_lmp} \hlstd{=} \hlkwd{predict}\hlstd{(reg_lmp))}
\hlcom{## Plot air conditioning vs. probability of air conditioning}
\hlstd{data} \hlopt{%>%}
  \hlkwd{ggplot}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= probability_ac_lmp,} \hlkwc{y} \hlstd{= air_conditioning))} \hlopt{+}
  \hlkwd{geom_point}\hlstd{()} \hlopt{+}
  \hlkwd{xlab}\hlstd{(}\hlstr{'Probability of air conditioning'}\hlstd{)} \hlopt{+}
  \hlkwd{ylab}\hlstd{(}\hlstr{'Air conditioining'}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Choice Probability Plot}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-8-1} 

\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Visualize Choice Probability with Bins}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Visualize probability of air conditioning using bins}
\hlcom{## Plot fraction vs. probability of air conditioning using bins}
\hlstd{data} \hlopt{%>%}
  \hlkwd{mutate}\hlstd{(}\hlkwc{bin} \hlstd{=} \hlkwd{cut}\hlstd{(probability_ac_lmp,}
                   \hlkwc{breaks} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0.05}\hlstd{),}
                   \hlkwc{labels} \hlstd{=} \hlnum{1}\hlopt{:}\hlnum{20}\hlstd{))} \hlopt{%>%}
  \hlkwd{group_by}\hlstd{(bin)} \hlopt{%>%}
  \hlkwd{summarize}\hlstd{(}\hlkwc{fraction_ac} \hlstd{=} \hlkwd{mean}\hlstd{(air_conditioning))} \hlopt{%>%}
  \hlkwd{mutate}\hlstd{(}\hlkwc{bin} \hlstd{=} \hlkwd{as.numeric}\hlstd{(bin),}
         \hlkwc{bin_mid} \hlstd{=} \hlnum{0.05} \hlopt{*} \hlstd{(bin} \hlopt{-} \hlnum{1}\hlstd{)} \hlopt{+} \hlnum{0.025}\hlstd{)} \hlopt{%>%}
  \hlkwd{ggplot}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= bin_mid,} \hlkwc{y} \hlstd{= fraction_ac))} \hlopt{+}
  \hlkwd{geom_point}\hlstd{()} \hlopt{+}
  \hlkwd{xlab}\hlstd{(}\hlstr{'Probability of air conditioning'}\hlstd{)} \hlopt{+}
  \hlkwd{ylab}\hlstd{(}\hlstr{'Fraction with air conditioning'}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Choice Probability Plot with Bins}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-10-1} 

\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Visualize Heteroskedastic Residuals}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Visualize heteroskedastic residuals}
\hlcom{## Calculate squared residuals}
\hlstd{data} \hlkwb{<-} \hlstd{data} \hlopt{%>%}
  \hlkwd{mutate}\hlstd{(}\hlkwc{sq_residual_lmp} \hlstd{= (air_conditioning} \hlopt{-} \hlstd{probability_ac_lmp)}\hlopt{^}\hlnum{2}\hlstd{)}
\hlcom{## Plot squared residual vs. probability of air conditioning}
\hlstd{data} \hlopt{%>%}
  \hlkwd{ggplot}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= probability_ac_lmp,} \hlkwc{y} \hlstd{= sq_residual_lmp))} \hlopt{+}
  \hlkwd{geom_point}\hlstd{()} \hlopt{+}
  \hlkwd{xlab}\hlstd{(}\hlstr{'Probability of air conditioning'}\hlstd{)} \hlopt{+}
  \hlkwd{ylab}\hlstd{(}\hlstr{'Squared residual'}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Heteroskedastic Residuals Plot}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-12-1} 

\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Heteroskedastic-Robust Standard Errors}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Calculate heteroskedastic-robust standard errors}
\hlcom{## Load lmtest and sandwich}
\hlkwd{library}\hlstd{(lmtest)}
\hlkwd{library}\hlstd{(sandwich)}
\hlcom{## Summarize regression results with robust standard errors}
\hlstd{reg_lmp} \hlopt{%>%}
  \hlkwd{coeftest}\hlstd{(}\hlkwc{vcov} \hlstd{=} \hlkwd{vcovHC}\hlstd{(reg_lmp))}
\end{alltt}
\begin{verbatim}
## 
## t test of coefficients:
## 
##                   Estimate  Std. Error t value  Pr(>|t|)    
## (Intercept)     1.67455330  0.20499142  8.1689 1.862e-15 ***
## cost_system    -0.00129176  0.00033683 -3.8351 0.0001389 ***
## cost_operating -0.00235491  0.00047989 -4.9071 1.194e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{LMP with Heterogeneous Coefficients}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Model air conditioning with heterogeneous cost coefficients}
\hlcom{## Regress air conditioning on costs divided by income}
\hlstd{reg_lmp_income} \hlkwb{<-} \hlstd{data} \hlopt{%>%}
  \hlkwd{lm}\hlstd{(}\hlkwc{formula} \hlstd{= air_conditioning} \hlopt{~} \hlkwd{I}\hlstd{(cost_system} \hlopt{/} \hlstd{income)} \hlopt{+}
       \hlkwd{I}\hlstd{(cost_operating} \hlopt{/} \hlstd{income))}
\hlcom{## Summarize regression results with robust standard errors}
\hlstd{reg_lmp_income} \hlopt{%>%}
  \hlkwd{coeftest}\hlstd{(}\hlkwc{vcov} \hlstd{=} \hlkwd{vcovHC}\hlstd{(reg_lmp_income))}
\end{alltt}
\begin{verbatim}
## 
## t test of coefficients:
## 
##                            Estimate Std. Error t value  Pr(>|t|)    
## (Intercept)               1.3242258  0.0609637 21.7215 < 2.2e-16 ***
## I(cost_system/income)    -0.0340815  0.0076552 -4.4521 1.015e-05 ***
## I(cost_operating/income) -0.1502152  0.0216845 -6.9273 1.113e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Visualize Income Data}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Visualize income variable}
\hlcom{## Plot kernel density of income}
\hlstd{data} \hlopt{%>%}
  \hlkwd{ggplot}\hlstd{(}\hlkwd{aes}\hlstd{(}\hlkwc{x} \hlstd{= income))} \hlopt{+}
  \hlkwd{geom_density}\hlstd{()} \hlopt{+}
  \hlkwd{xlab}\hlstd{(}\hlstr{'Income'}\hlstd{)} \hlopt{+}
  \hlkwd{ylab}\hlstd{(}\hlstr{'Kernel density'}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-15-1} 

\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Marginal Effects Depending on Income}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Calculate marginal effects of cost variables}
\hlcom{## Calculate marginal effects of costs when income == 60}
\hlkwd{coef}\hlstd{(reg_lmp_income)[}\hlnum{2}\hlopt{:}\hlnum{3}\hlstd{]} \hlopt{/} \hlnum{60}
\end{alltt}
\begin{verbatim}
##    I(cost_system/income) I(cost_operating/income) 
##            -0.0005680255            -0.0025035870
\end{verbatim}
\begin{alltt}
\hlcom{## Calculate marginal effects of costs when income == 30}
\hlkwd{coef}\hlstd{(reg_lmp_income)[}\hlnum{2}\hlopt{:}\hlnum{3}\hlstd{]} \hlopt{/} \hlnum{30}
\end{alltt}
\begin{verbatim}
##    I(cost_system/income) I(cost_operating/income) 
##             -0.001136051             -0.005007174
\end{verbatim}
\begin{alltt}
\hlcom{## Calculate marginal effects of costs when income == 90}
\hlkwd{coef}\hlstd{(reg_lmp_income)[}\hlnum{2}\hlopt{:}\hlnum{3}\hlstd{]} \hlopt{/} \hlnum{90}
\end{alltt}
\begin{verbatim}
##    I(cost_system/income) I(cost_operating/income) 
##            -0.0003786837            -0.0016690580
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{LMP with Age as an Explanatory Variable}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### Model air conditioning with residents as an explanatory variable}
\hlcom{## Regress air conditoning on scaled costs and number of residents}
\hlstd{reg_lmp_residents} \hlkwb{<-} \hlstd{data} \hlopt{%>%}
  \hlkwd{lm}\hlstd{(}\hlkwc{formula} \hlstd{= air_conditioning} \hlopt{~} \hlkwd{I}\hlstd{(cost_system} \hlopt{/} \hlstd{income)} \hlopt{+}
       \hlkwd{I}\hlstd{(cost_operating} \hlopt{/} \hlstd{income)} \hlopt{+} \hlstd{residents)}
\hlcom{## Summarize regression results with robust standard errors}
\hlstd{reg_lmp_residents} \hlopt{%>%}
  \hlkwd{coeftest}\hlstd{(}\hlkwc{vcov} \hlstd{=} \hlkwd{vcovHC}\hlstd{(reg_lmp_residents))}
\end{alltt}
\begin{verbatim}
## 
## t test of coefficients:
## 
##                            Estimate Std. Error t value  Pr(>|t|)    
## (Intercept)               0.7646358  0.0772214  9.9019 < 2.2e-16 ***
## I(cost_system/income)    -0.0346750  0.0082373 -4.2095 2.955e-05 ***
## I(cost_operating/income) -0.1542973  0.0189966 -8.1224 2.640e-15 ***
## residents                 0.3432309  0.0166628 20.5987 < 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\end{document}
