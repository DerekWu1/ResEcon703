\documentclass{beamer}
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{footline}
{
    \leavevmode%
    \hbox{%
    \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.05\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
        \insertframenumber{}
    \end{beamercolorbox}}%
    \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{parse-numbers=false}

\setlength{\OuterFrameSep}{-2pt}
\makeatletter
\preto{\@verbatim}{\topsep=-10pt \partopsep=-10pt }
\makeatother

\title[Lecture 8:\ Logit Estimation]{Lecture 8:\ Logit Estimation}
\author[ResEcon 703:\ Advanced Econometrics]{ResEcon 703:\ Topics in Advanced Econometrics}
\date{Matt Woerman\\University of Massachusetts Amherst}

\begin{document}
<<include = FALSE>>=
library(knitr)
opts_chunk$set(size = 'footnotesize')
options(width = 70)
@

{\setbeamertemplate{footline}{} 
\begin{frame}[noframenumbering]
    \titlepage
\end{frame}
}

\begin{frame}\frametitle{Agenda}
    Last time
    \begin{itemize}
        \item Numerical Optimization
    \end{itemize}
    \vspace{2ex}
    Today
    \begin{itemize}
    	\item Logit Estimation
    	\item Logit Estimation Example in R
    \end{itemize}
    \vspace{2ex}
    Upcoming
    \begin{itemize}
        \item Reading for next time
        \begin{itemize}
            \item Greene textbook, Chapters 7.2.2--7.2.8 (Chapters 7.2.2--7.2.6 in the Seventh Edition)
        \end{itemize}
        \item Problem sets
        \begin{itemize}
            \item Problem Set 2 will be posted soon, due October 17
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Course So Far}
    So far we have covered
    \begin{itemize}
    	\item Discrete choice framework
    	\item Random utility model
    	\item Logit model
    	\item Maximum likelihood estimation
    	\item Numerical optimization
    \end{itemize}
    \vspace{3ex}
    We can finally put all these pieces together and estimate a model ourselves!
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Logit Estimation
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Logit Likelihood Function}
    Under the assumptions of the logit model, the probability that decision maker $n$ chooses alternative $i$
    $$P_{ni} = \frac{e^{V_{ni}}}{\sum_{j = 1}^J e^{V_{nj}}}$$
    We can express the probability of decision maker $n$ choosing the alternative that was chosen, where $y_{ni} = 1$ if and only if $n$ chose $i$ 
    $$\prod_{i = 1}^J (P_{ni})^{y_{ni}}$$
    Then the likelihood function for the entire sample is
    $$L(\beta) = \prod_{n = 1}^N \prod_{i = 1}^J (P_{ni})^{y_{ni}}$$
\end{frame}

\begin{frame}\frametitle{Logit Log-Likelihood Function}
    Then the logit log-likelihood function is
    $$LL(\beta) = \sum_{n = 1}^N \sum_{i = 1}^J y_{ni} \ln P_{ni}$$
    The MLE is the set of parameters, $\hat{\beta}$, that maximize this function
\end{frame}

\begin{frame}\frametitle{Logit Moment Condition}
    The first-order condition for maximization is
    $$\frac{\partial LL(\beta)}{\partial \beta} = 0$$
    If we assume representative utility is linear, $V_{ni} = \beta' x_{ni}$, (and after some substitution and simplification) this first-order condition is equivalent to
    $$\sum_{n = 1}^N \sum_{i = 1}^J (y_{ni} - P_{ni}) x_{ni} = 0$$
    This is the sample covariance of the ``residuals,'' $y_{ni} - P_{ni}$, and the data, $x_{ni}$
    \begin{itemize}
    	\item This is a moment condition that we could use for GMM
    	\begin{itemize}
    		\item More on that in a couple weeks...
    	\end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Non-Random Sampling of Decision Makers}
    The previous slides all require that sampling is random (or at least exogenous to the choice)
    \begin{itemize}
    	\item If your sample is endogenous to the choice, then coefficients may be inconsistent
    	\item Example: What could go wrong if you take a survey of commute choices, but you take the survey at the bus stop?
    \end{itemize}
    \vspace{3ex}
    You can recover consistent estimates from a non-random sample, but that requires a more complex estimation procedure
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Logit Estimation Example in R
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Multinomial Logit Estimation Example}
    We are again studying how consumers make choices about expensive and highly energy-consuming systems in their homes. We have data on 900 households in California and the type of heating system in their home. Each household has the following choice set, and we observe the following data \\
    \vspace{3ex}
    \begin{columns}
    	\begin{column}{0.5\textwidth}
		    Choice set
		    \begin{itemize}
		    	\item GC: gas central
		    	\item GR: gas room
		    	\item EC: electric central
		    	\item ER: electric room
		    	\item HP: heat pump
		    \end{itemize}
		    \vspace{8ex}
	    \end{column}
	    \begin{column}{0.5\textwidth}
		    Alternative-specific data
		    \begin{itemize}
		    	\item IC: installation cost
		    	\item OC: annual operating cost
		    \end{itemize}
		    \vspace{2ex}
		    Household demographic data
		    \begin{itemize}
		    	\item income: annual income
		    	\item agehed: age of household head
		    	\item rooms: number of rooms
                \item region: home location
		    \end{itemize}
		\end{column}
    \end{columns}
\end{frame}

\begin{frame}[fragile]\frametitle{Load Dataset}
    <<message = FALSE>>=
    ## Load tidyverse and mlogit
    library(tidyverse)
    library(mlogit)
    ## Load dataset from mlogit package
    data('Heating', package = 'mlogit')
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Dataset}
    <<>>=
    ## Look at dataset
    as_tibble(Heating)
    @
\end{frame}

\begin{frame}\frametitle{Three Models to Estimate}
    \vspace{-4ex}
    \begin{align*}
        \intertext{Base model}
        U_{nj} &= \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \varepsilon_{nj} \\
        \vspace{2ex}
        \intertext{Heterogeneous coefficients model}
        U_{nj} &= \alpha_j + \frac{\beta_1}{I_n} IC_{nj} + \frac{\beta_2}{I_n} OC_{nj} + \varepsilon_{nj} \\
        \vspace{2ex}
        \intertext{Alternative-specific coefficients model}
        U_{nj} &= \alpha_j + \beta_1 IC_{nj} + \beta_2 OC_{nj} + \beta_{3j} R_n + \varepsilon_{nj}
    \end{align*}
\end{frame}

\begin{frame}[fragile]\frametitle{Optimization in R}
    <<eval = FALSE>>=
    ### Optimization in R
    ## Help file for the optimization function, optim
    ?optim
    ## Arguments for optim function
    optim(par, fn, gr, ..., method, lower, upper, control, hessian)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Function to Calculate Log-Likelihood}
    \vspace{1ex}
    <<size = 'tiny'>>=
    ### Calculate MLE for multinomial logit heating choice using cost data and 
    ### alternative effects
    ## Function to calculate log-likelihood using cost data and alternative effects
    log_likelihood_wide <- function(parameters, data){
      ## Extract individual parameters
      alpha_1 <- parameters[1]
      alpha_2 <- parameters[2]
      alpha_3 <- parameters[3]
      alpha_4 <- parameters[4]
      beta_1 <- parameters[5]
      beta_2 <- parameters[6]
      ## Calculate utility for each alternative given the parameters
      data <- data %>% 
        mutate(utility_ec = alpha_1 + beta_1 * ic.ec + beta_2 * oc.ec,
               utility_er = alpha_2 + beta_1 * ic.er + beta_2 * oc.er,
               utility_gc = alpha_3 + beta_1 * ic.gc + beta_2 * oc.gc,
               utility_gr = alpha_4 + beta_1 * ic.gr + beta_2 * oc.gr,
               utility_hp = beta_1 * ic.hp + beta_2 * oc.hp)
      ## Calculate logit probability denominator given the parameters
      data <- data %>% 
        mutate(probability_denominator = exp(utility_ec) + exp(utility_er) +
                 exp(utility_gc) + exp(utility_gr) + exp(utility_hp))
      ## Calculate logit probability numerator given the parameters
      data <- data %>% 
        mutate(probability_numerator = exp(utility_ec) * (depvar == 'ec') +
                 exp(utility_er) * (depvar == 'er') + 
                 exp(utility_gc) * (depvar == 'gc') +
                 exp(utility_gr) * (depvar == 'gr') + 
                 exp(utility_hp) * (depvar == 'hp'))
      ## Calculate log of logit choice probability given the parameters
      data <- data %>% 
        mutate(probability_choice = probability_numerator / probability_denominator,
               log_probability_choice = log(probability_choice))
      ## Calculate the log-likelihood for these parameters
      log_likelihood <- sum(data$log_probability_choice)
      return(-log_likelihood)
    }
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Estimate Logit Model}
    <<>>=
    ## Maximize the log-likelihood function
    model_wide <- optim(rep(0, 6), log_likelihood_wide, data = Heating, 
                        method = 'BFGS', hessian = TRUE)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Estimation Results}
    <<size = 'scriptsize'>>=
    ## Show optimization results
    model_wide
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Maximum Likelihood Estimator and Hessian}
    <<>>=
    ## Show MLE parameters
    model_wide$par
    ## Show Hessian at the MLE
    model_wide$hessian
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Variance-Covariance Matrix}
    \vspace{1ex}
    <<>>=
    ## Calculate MLE variance-covariance matrix
    model_wide$hessian %>% 
      solve()
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Standard Errors}
    \vspace{1ex}
    <<>>=
    ## Calculate MLE standard errors
    model_wide$hessian %>% 
      solve() %>% 
      diag() %>% 
      sqrt()
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Heterogeneous Coefficients}
    \vspace{1ex}
    <<size = 'tiny'>>=
    ### Calculate MLE for multinomial logit heating choice using cost data scaled
    ### by income and alternative effects
    ## Function to calculate log-likelihood using two variables and four 
    ## alternative effects
    log_likelihood_long <- function(parameters, data){
      ## Extract individual parameters
      alphas <- parameters[1:4]
      beta_1 <- parameters[5]
      beta_2 <- parameters[6]
      ## Assign constant parameters to alternatives
      data <- data %>% 
        group_by(idcase) %>% 
        arrange(idcase, alt) %>% 
        mutate(constant = c(alphas, 0)) %>% 
        ungroup()
      ## Calculate utility for each alternative given the parameters
      data <- data %>% 
        mutate(utility = constant + beta_1 * var_1 + beta_2 * var_2)
      ## Calculate logit probability denominator given the parameters
      data <- data %>% 
        group_by(idcase) %>% 
        mutate(probability_denominator = sum(exp(utility))) %>% 
        ungroup()
      ## Filter on only the alternative that was chosen
      data <- data %>% 
        filter(choice == TRUE)
      ## Calculate log of logit choice probability given the parameters
      data <- data %>%
        mutate(probability_choice = exp(utility) / probability_denominator,
               log_probability_choice = log(probability_choice))
      ## Calculate the log-likelihood for these parameters
      log_likelihood <- sum(data$log_probability_choice)
      return(-log_likelihood)
    }
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Heterogeneous Coefficients Optimization}
    <<>>=
    ## Gather heating dataset into a long dataset
    heating_long <- Heating %>% 
      gather(key, value, starts_with('ic.'), starts_with('oc.')) %>% 
      separate(key, c('cost', 'alt')) %>% 
      spread(cost, value) %>% 
      mutate(choice = (depvar == alt)) %>% 
      select(-depvar) %>% 
      mutate(var_1 = ic / income, var_2 = oc / income)
    ## Maximize the log-likelihood function
    model_long <- optim(rep(0, 6), log_likelihood_long, data = heating_long, 
                        method = 'BFGS', hessian = TRUE)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Heterogeneous Coefficients MLE Results}
    <<>>=
    ## Show MLE parameters
    model_long$par
    ## Calculate MLE standard errors
    model_long$hessian %>% 
      solve() %>% 
      diag() %>% 
      sqrt()
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients}
    <<size = 'tiny'>>=
    ### Calculate MLE for multinomial logit heating choice using cost data, 
    ### alternative effects, and alternative-specific coefficients on rooms
    ## Function to calculate log-likelihood using flexible matrices
    log_likelihood_matrix <- function(parameters, data){
      ## Extract explanatory variables
      data_x <- data %>% 
        map(1)
      ## Extract choice data
      data_y <- data %>% 
        map(2)
      ## Calculate utility for each alternative given the parameters
      utility <- data_x %>% 
        map(~ .x %*% parameters)
      ## Calculate logit probability denominator given the parameters
      probability_denominator <- utility %>% 
        map(~ sum(exp(.x))) %>% 
        unlist()
      ## Calculate logit probability numerator given the parameters
      probability_numerator <- utility %>% 
        map2(data_y, ~ exp(sum(.x * .y))) %>% 
        unlist()
      ## Calculate logit choice probability given the parameters
      probability_choice <-  probability_numerator / probability_denominator
      ## Calculate log of logit choice probability given the parameters
      log_probability_choice <- log(probability_choice)
      ## Calculate the log-likelihood for these parameters
      log_likelihood <- sum(log_probability_choice)
      return(-log_likelihood)
    }
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients Estimation Data}
    <<size = 'tiny'>>=
    ## Split heating dataset into list of household data frames
    heating_split <- heating_long %>% 
      group_by(idcase) %>% 
      arrange(idcase, alt) %>% 
      group_split()
    ## Crate matrix of dummy variables (intercepts) to bind to data
    constant_matrix <- diag(4) %>% 
      rbind(c(0, 0, 0, 0))
    ## Function to create list of datasets for estimation
    create_data_matrix <- function(data){
      data_x <- data %>% 
        select(ic, oc) %>% 
        as.matrix()
      data_x <- constant_matrix %>% 
        cbind(data_x)
      rooms <- data$rooms[1]
      data_x <- 
        data_x %>% 
        cbind(rooms * constant_matrix)
      data_y <- data %>% 
        select(choice) %>% 
        mutate(choice = 1 * choice) %>% 
        pull(choice)
      return(list(x = data_x, y = data_y))
    }
    ## Create list of datasets for estimation
    heating_matrix <- heating_split %>% 
      map(.x = ., .f = ~ create_data_matrix(.x))
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients Optimization}
    <<>>=
    ## Maximize the log-likelihood function
    model_matrix <- optim(rep(0, 10), log_likelihood_matrix, 
                          data = heating_matrix, 
                          method = 'BFGS', hessian = TRUE)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Alternative-Specific Coefficients MLE Results}
    <<>>=
    ## Show MLE parameters
    model_matrix$par
    ## Calculate MLE standard errors
    model_matrix$hessian %>% 
      solve() %>% 
      diag() %>% 
      sqrt()
    @
\end{frame}

\begin{frame}[fragile]\frametitle{Likelihood Ratio Test for Joint Significance}
    <<>>=
    ### Test that alternative-specific coefficients are jointly significant
    ## Calculate likelihood ratio test statistic
    lr_test_statistic <- -2 * (model_matrix$value - model_wide$value)
    lr_test_statistic
    ## Find chi-squared critical value for df = 4
    qchisq(0.95, 4)
    ## Test if likelihood ratio test statitsic is greater than critical value
    lr_test_statistic > qchisq(0.95, 4)
    ## Calculate p-value of test
    1 - pchisq(lr_test_statistic, 4)
    @
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Bayer et al. (2009)
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Bayer et al. (2009)}
    Research question
    \begin{itemize}
        \item How much do people value air quality in the place where they choose to live?
    \end{itemize}
    \vspace{2ex}
    Empirical methods
    \begin{itemize}
      \item Model the location choice of households as a multinomial logit model to recover composite city-level valuations
      \item Regress the composite city-level value on city attributes, including PM10 concentration, to estimate the value of air quality
    \end{itemize}
    \vspace{2ex}
    Results
    \begin{itemize}
      \item Willingness to pay for air quality is \$149--\$185 per $\mu \text{g} / \text{m}^3$ of PM10, or an elasticity of 0.34--0.42
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Residential Location Choice}
    The hedonic pricing model is the standard model used to estimate the value of air quality
    \begin{itemize}
      \item The hedonic model is based on the idea that a home is a bundle of attributes, each of which contributes to the price of the home, so we can estimate attribute values from home prices
      \item An underlying assumption of this model is that moving is costless
    \end{itemize}
    \vspace{2ex}
    An alternative approach developed by Bayer et al.\ uses multinomial logit
    \begin{itemize}
      \item The choice of where to live is clearly a discrete choice
      \item But air pollution is endogenous, and it is challenging to instrument within a multinomial model
      \item Bayer et al.\ develop this approach to first estimate a composite city-specific valuation, and then regress this value on attributes, which does allow for IV
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{General Comments and Questions}
    Clever combination of structural estimation (first stage) and a linear IV model (second stage)
    \begin{itemize}
      \item This is becoming more common in the absence of exogenous variation: recover structural parameters and then deal with endogeneity
      \item Or you could use GMM...more on this later
    \end{itemize}
    \vspace{2ex}
    Some assumptions and implications of this model
    \begin{itemize}
      \item Income counterfactuals can be estimated from others with similar characteristics
      \item All households spend the same fraction of income on housing (20\%)
      \item Standard logit assumption of i.i.d.\ errors
    \end{itemize}
    \vspace{2ex}
    Do we believe
    \begin{itemize}
      \item These assumptions?
      \item The IV strategy?
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Announcements}
    Reading for next time
    \begin{itemize}
        \item Greene textbook, Chapters 7.2.2--7.2.8 (Chapters 7.2.2--7.2.6 in the Seventh Edition)
    \end{itemize}
    \vspace{3ex}
    Upcoming
    \begin{itemize}
        \item Problem Set 2 will be posted soon, due October 17
    \end{itemize}
\end{frame}

\end{document}
