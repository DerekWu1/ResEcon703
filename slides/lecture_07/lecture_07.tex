\documentclass{beamer}
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{footline}
{
    \leavevmode%
    \hbox{%
    \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.05\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
        \insertframenumber{}
    \end{beamercolorbox}}%
    \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{parse-numbers=false}

%\setlength{\OuterFrameSep}{-2pt}
%\makeatletter
%\preto{\@verbatim}{\topsep=-10pt \partopsep=-10pt }
%\makeatother

\title[Lecture 7:\ Numerical Optimization]{Lecture 7:\ Numerical Optimization}
\author[ResEcon 703:\ Advanced Econometrics]{ResEcon 703:\ Topics in Advanced Econometrics}
\date{Matt Woerman\\University of Massachusetts Amherst}

\begin{document}

{\setbeamertemplate{footline}{} 
\begin{frame}[noframenumbering]
    \titlepage
\end{frame}
}

\begin{frame}\frametitle{Agenda}
    Last time
    \begin{itemize}
        \item Nonlinear Regression Models
        \item Maximum Likelihood Estimation
    \end{itemize}
    \vspace{2ex}
    Today
    \begin{itemize}
    	\item Numerical Optimization
    \end{itemize}
    \vspace{2ex}
    Upcoming
    \begin{itemize}
        \item Reading for next time
        \begin{itemize}
            \item Train textbook, Chapters 3.7--3.8
            \item Bayer et al. (2009)
        \end{itemize}
        \item Problem sets
        \begin{itemize}
            \item Problem Set 1 was due at 10 am today
            \item Problem Set 2 will be posted soon, due October 17
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Maximum Likelihood Recap}
    The probability density function (PDF) for a random variable, $y$, conditioned on a set of parameters, $\theta$, is
    $$f(y \mid \theta)$$ \\
    The log-likelihood function for $\theta$ conditional on observed data is
    $$\ln L(\theta \mid y) = \sum_{i = 1}^n \ln f(y_i \mid \theta)$$ \\
    The maximum likelihood estimator (MLE) is the value(s) of $\theta$ that maximizes this function
    $$\hat{\theta} = \argmax_\theta \ln L(\theta \mid y)$$
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Numerical Optimization
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Numerical Optimization}
    Most structural estimation requires maximizing (or minimizing) an objective function
    \begin{itemize}
        \item For MLE, we want to maximize the log-likelihood function
    \end{itemize}
    \vspace{3ex}
    In theory, this is a relatively simple proposition
    \begin{itemize}
        \item Some optimization problems have a closed-form expression
        \item For only one or two parameters, a grid search may suffice
    \end{itemize}
    \vspace{3ex}
    In practice, finding the correct parameters in an efficient way can be challenging
    \begin{itemize}
        \item Especially when you are optimizing over a vector of many parameters and using a complex objective function
        \item Numerical optimization algorithms can solve this problem
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Numerical Optimization Steps}
    We want to find the set of $K$ parameters, $\hat{\beta}$, that maximize the objective function, $\ell(\beta)$
    \begin{enumerate}
        \item Begin with some initial parameter values, $\beta_0$
        \item Check if you can ``walk up'' to a higher value
        \item If so, take a step in the right direction to $\beta_{t + 1}$
        \item Repeat (2) and (3) until you are at the maximum
    \end{enumerate}
    \vspace{3ex}
    But which direction should you step and how big of a step should you take from $\beta_t$ to $\beta_{t + 1}$?
    \begin{itemize}
        \item If your steps are too small, optimization can take too long
        \item If your steps are too big, you may never converge to a solution
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Gradient and Hessian}
    The gradient tells us which direction to step
    $$g_t = \left( \frac{\partial \ell(\beta)}{\partial \beta} \right)_{\beta_t}$$ \\
    \begin{itemize}
        \item The gradient is a $K \times 1$ vector tells us which direction to move each parameter to increase the objective function
    \end{itemize}
    \vspace{3ex}
    The Hessian tells us how far to step
    $$H_t = \left( \frac{\partial^2 \ell(\beta)}{\partial \beta \partial \beta'} \right)_{\beta_t}$$ \\
    \begin{itemize}
        \item The Hessian is a $K \times K$ matrix that gives us information about the ``curvature'' of the objective function in all dimensions
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Newton-Raphson Method}
    The Newton-Raphson method is based on the second-order Taylor's approximation of $\ell(\beta_{t + 1})$ around $\ell(\beta_t)$
    $$\ell(\beta_{t + 1}) = \ell(\beta_t) + (\beta_{t + 1} - \beta_t)' g_t + \frac{1}{2} (\beta_{t + 1} - \beta_t)' H_t (\beta_{t + 1} - \beta_t)$$
    We step to the value of $\beta_{t + 1}$ that maximizes this approximation
    $$\frac{\partial \ell(\beta_{t + 1})}{\partial \beta_{t + 1}} = 0 \quad \Rightarrow \quad \beta_{t + 1} = \beta_t + \lambda (-H_t)^{-1} g_t$$
    This method steps to what would be the maximizing vector of parameters if the objective function was quadratic
    \begin{itemize}
        \item If the objective function is not close to quadratic, steps can be too small or too large
        \begin{itemize}
            \item You can iteratively scale the step size to be larger or smaller using $\lambda$
        \end{itemize}
        \item Steps can go in the wrong direction if the objective function is not globally concave
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Score}
    When we are maximizing a log-likelihood function, we can speed up optimization by exploiting the fact that we are maximizing a sum of individual-specific terms \\
    \vspace{2ex}
    To do this, we calculate the score for each individual
    $$s_n(\beta_t) = \left( \frac{\partial \ln L_n(\beta)}{\partial \beta} \right)_{\beta_t}$$
    If we think of maximizing the average log-likelihood
    $$LL(\beta) = \frac{\sum_{n = 1}^N \ln L_n(\beta)}{N}$$
    then the gradient is equal to the average score
    $$g_t = \frac{\sum_{n = 1}^N s_n(\beta_t)}{N}$$
\end{frame}

\begin{frame}\frametitle{BHHH (Berndt-Hall-Hall-Hausman) Method}
    The BHHH method uses the the average outer product of scores, which is related to the variance and covariance of scores, to calculate step size
    $$B_t = \frac{\sum_{n = 1}^N s_n(\beta_t) s_n(\beta_t)'}{N}$$
    The BHHH method uses this average outer product in place of the Hessian
    $$\beta_{t + 1} = \beta_t + \lambda B_t^{-1} g_t$$ \\
    \vspace{2ex}
    Advantages of BHHH over NR
    \begin{itemize}
        \item $B_t$ is faster to calculate than $H_t$
        \item $B_t$ is always positive definite, so no concavity problems
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Other Methods}
    \begin{itemize}
        \item BHHH-2
        \item Steepest ascent
        \item DFP (Davidson-Fletcher-Powell)
        \item BFGS (Broyden-Fletcher-Goldfarb-Shanno)
        \item Nelder-Mead
        \item Conjugate gradients
        \item Limited-memory BFGS
        \item Simulated annealing
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Convergence Criterion}
    When do we stop taking steps?
    \begin{itemize}
        \item In theory, when the gradient vector equals zero
        \item In practice, you will never hit the precise vector of parameters (down to the 15th decimial point) that yields a gradient of zero
        \item So we stop taking steps when we get ``close enough''
    \end{itemize}
    \vspace{2ex}
    How do we know when we are ``close enough?''
    \begin{itemize}
        \item Calculate a statistic, $m_t$, to evaluate convergence
        $$m_t = g_t' (-H_t^{-1})g_t$$
        \item Stop when this statistic gets sufficiently small
        $$m_t < \breve{m} = 0.0001$$
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Global or Local Maximum}
    Global maximum
    \begin{itemize}
        \item The largest value of the objective function over all possible sets of parameter values
        \item This is the maximum you want to converge to
        \item When the objective function is globally concave (as in the logit model with linear utility), you will always hit the global maximum
    \end{itemize}
    \vspace{1ex}
    Local maximum
    \begin{itemize}
        \item The largest value of the objective function within a range of parameter values, but not the global maximum
        \item Optimization algorithms will sometimes converge to a local maximum instead of the global maximum
        \item More complex objective functions have local maxima
    \end{itemize}
    \vspace{1ex}
    Try different starting values to ensure you have converged to the global maximum, not a local maximum
\end{frame}

\begin{frame}\frametitle{Announcements}
    Reading for next time
    \begin{itemize}
        \item Train textbook, Chapters 3.7--3.8
        \item Bayer et al. (2009)
    \end{itemize}
    \vspace{3ex}
    Office hours
    \begin{itemize}
        \item Reminder: Tuesdays at 2:00-3:00 in 218 Stockbridge
    \end{itemize}
    \vspace{3ex}
    Upcoming
    \begin{itemize}
        \item Problem Set 2 will be posted soon, due October 17
    \end{itemize}
\end{frame}

\end{document}