\documentclass{beamer}
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{footline}
{
    \leavevmode%
    \hbox{%
    \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.05\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
        \insertframenumber{}
    \end{beamercolorbox}}%
    \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\renewcommand{\familydefault}{\sfdefault}

\DeclareMathOperator*{\argmax}{argmax}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{parse-numbers=false}

\setlength{\OuterFrameSep}{-2pt}
\makeatletter
\preto{\@verbatim}{\topsep=-10pt \partopsep=-10pt }
\makeatother

\title[Lecture 7:\ Numerical Optimization]{Lecture 7:\ Numerical Optimization}
\author[ResEcon 703:\ Advanced Econometrics]{ResEcon 703:\ Topics in Advanced Econometrics}
\date{Matt Woerman\\University of Massachusetts Amherst}

\begin{document}
<<include = FALSE>>=
library(knitr)
opts_chunk$set(size = 'footnotesize')
options(width = 70)
@

{\setbeamertemplate{footline}{} 
\begin{frame}[noframenumbering]
    \titlepage
\end{frame}
}

\begin{frame}\frametitle{Agenda}
    Last time
    \begin{itemize}
    	\item Nonlinear Regression Models
        \item Maximum Likelihood Estimation
    \end{itemize}
    \vspace{2ex}
    Today
    \begin{itemize}
    	\item Numerical Optimization
    	\item Recap of Random Utility and Logit Models
    \end{itemize}
    \vspace{2ex}
    Upcoming
    \begin{itemize}
        \item Reading for next time
        \begin{itemize}
            \item Train textbook, Chapters 3.7--3.8
            \item Bayer et al. (2009)
        \end{itemize}
        \item Problem sets
        \begin{itemize}
            \item Problem Set 1 solutions are posted
            \item Problem Set 2 will be posted soon, due October 17
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Maximum Likelihood Recap}
    The probability density function (PDF) for a random variable, $y$, conditioned on a set of parameters, $\theta$, is
    $$f(y \mid \theta)$$ \\
    The log-likelihood function for $\theta$ conditional on observed data is
    $$\ln L(\theta \mid y) = \sum_{i = 1}^n \ln f(y_i \mid \theta)$$ \\
    The maximum likelihood estimator (MLE) is the value(s) of $\theta$ that maximizes this function
    $$\hat{\theta} = \argmax_\theta \ln L(\theta \mid y)$$
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Numerical Optimization
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Numerical Optimization}
    Most structural estimation requires maximizing (or minimizing) an objective function
    \begin{itemize}
        \item For MLE, we want to maximize the log-likelihood function
    \end{itemize}
    \vspace{3ex}
    In theory, this is a relatively simple proposition
    \begin{itemize}
        \item Some optimization problems have a closed-form expression
        \item For only one or two parameters, a grid search may suffice
    \end{itemize}
    \vspace{3ex}
    In practice, finding the correct parameters in an efficient way can be challenging
    \begin{itemize}
        \item Especially when you are optimizing over a vector of many parameters and using a complex objective function
        \item Numerical optimization algorithms can solve this problem
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Numerical Optimization Steps}
    We want to find the set of $K$ parameters, $\hat{\beta}$, that maximize the objective function, $\ell(\beta)$
    \begin{enumerate}
        \item Begin with some initial parameter values, $\beta_0$
        \item Check if you can ``walk up'' to a higher value
        \item If so, take a step in the right direction to $\beta_{t + 1}$
        \item Repeat (2) and (3) until you are at the maximum
    \end{enumerate}
    \vspace{3ex}
    But which direction should you step and how big of a step should you take from $\beta_t$ to $\beta_{t + 1}$?
    \begin{itemize}
        \item If your steps are too small, optimization can take too long
        \item If your steps are too big, you may never converge to a solution
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Gradient and Hessian}
    The gradient tells us which direction to step
    $$g_t = \left( \frac{\partial \ell(\beta)}{\partial \beta} \right)_{\beta_t}$$ \\
    \begin{itemize}
        \item The gradient is a $K \times 1$ vector tells us which direction to move each parameter to increase the objective function
    \end{itemize}
    \vspace{3ex}
    The Hessian tells us how far to step
    $$H_t = \left( \frac{\partial^2 \ell(\beta)}{\partial \beta \partial \beta'} \right)_{\beta_t}$$ \\
    \begin{itemize}
        \item The Hessian is a $K \times K$ matrix that gives us information about the ``curvature'' of the objective function in all dimensions
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Newton-Raphson Method}
    The Newton-Raphson method is based on the second-order Taylor's approximation of $\ell(\beta_{t + 1})$ around $\ell(\beta_t)$
    $$\ell(\beta_{t + 1}) = \ell(\beta_t) + (\beta_{t + 1} - \beta_t)' g_t + \frac{1}{2} (\beta_{t + 1} - \beta_t)' H_t (\beta_{t + 1} - \beta_t)$$
    We step to the value of $\beta_{t + 1}$ that maximizes this approximation
    $$\frac{\partial \ell(\beta_{t + 1})}{\partial \beta_{t + 1}} = 0 \quad \Rightarrow \quad \beta_{t + 1} = \beta_t + \lambda (-H_t)^{-1} g_t$$
    This method steps to what would be the maximizing vector of parameters if the objective function was quadratic
    \begin{itemize}
        \item If the objective function is not close to quadratic, steps can be too small or too large
        \begin{itemize}
            \item You can iteratively scale the step size to be larger or smaller using $\lambda$
        \end{itemize}
        \item Steps can go in the wrong direction if the objective function is not globally concave
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Score}
    When we are maximizing a log-likelihood function, we can speed up optimization by exploiting the fact that we are maximizing a sum of individual-specific terms \\
    \vspace{2ex}
    To do this, we calculate the score for each individual
    $$s_n(\beta_t) = \left( \frac{\partial \ln L_n(\beta)}{\partial \beta} \right)_{\beta_t}$$
    If we think of maximizing the average log-likelihood
    $$LL(\beta) = \frac{\sum_{n = 1}^N \ln L_n(\beta)}{N}$$
    then the gradient is equal to the average score
    $$g_t = \frac{\sum_{n = 1}^N s_n(\beta_t)}{N}$$
\end{frame}

\begin{frame}\frametitle{BHHH (Berndt-Hall-Hall-Hausman) Method}
    The BHHH method uses the the average outer product of scores, which is related to the variance and covariance of scores, to calculate step size
    $$B_t = \frac{\sum_{n = 1}^N s_n(\beta_t) s_n(\beta_t)'}{N}$$
    The BHHH method uses this average outer product in place of the Hessian
    $$\beta_{t + 1} = \beta_t + \lambda B_t^{-1} g_t$$ \\
    \vspace{2ex}
    Advantages of BHHH over NR
    \begin{itemize}
        \item $B_t$ is faster to calculate than $H_t$
        \item $B_t$ is always positive definite, so no concavity problems
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Other Methods}
    \begin{itemize}
        \item BHHH-2
        \item Steepest ascent
        \item DFP (Davidson-Fletcher-Powell)
        \item BFGS (Broyden-Fletcher-Goldfarb-Shanno)
        \item Nelder-Mead
        \item Conjugate gradients
        \item Limited-memory BFGS
        \item Simulated annealing
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Convergence Criterion}
    When do we stop taking steps?
    \begin{itemize}
        \item In theory, when the gradient vector equals zero
        \item In practice, you will never hit the precise vector of parameters (down to the 15th decimial point) that yields a gradient of zero
        \item So we stop taking steps when we get ``close enough''
    \end{itemize}
    \vspace{2ex}
    How do we know when we are ``close enough?''
    \begin{itemize}
        \item Calculate a statistic, $m_t$, to evaluate convergence
        $$m_t = g_t' (-H_t^{-1})g_t$$
        \item Stop when this statistic gets sufficiently small
        $$m_t < \breve{m} = 0.0001$$
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Global or Local Maximum}
    Global maximum
    \begin{itemize}
        \item The largest value of the objective function over all possible sets of parameter values
        \item This is the maximum you want to converge to
        \item When the objective function is globally concave (as in the logit model with linear utility), you will always hit the global maximum
    \end{itemize}
    \vspace{1ex}
    Local maximum
    \begin{itemize}
        \item The largest value of the objective function within a range of parameter values, but not the global maximum
        \item Optimization algorithms will sometimes converge to a local maximum instead of the global maximum
        \item More complex objective functions have local maxima
    \end{itemize}
    \vspace{1ex}
    Try different starting values to ensure you have converged to the global maximum, not a local maximum
\end{frame}

\begin{frame}\frametitle{}
    \vfill
    \centering
    \begin{beamercolorbox}[center]{title}
        \Large Recap of Random Utility and Logit Models
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}\frametitle{Random Utility Model}
	Discrete choice from the perspective of the decision maker
	\begin{itemize}
		\item Decision maker, $n$, faces a choice among $J$ alternatives
		\item Alternative $j$ provides utility $U_{nj}$
		\item The decision maker chooses the alternative with the greatest utility
	\end{itemize}
	\vspace{2ex}
	Discrete choice from the perspective of the econometrician
	\begin{itemize}
		\item We do not observe utility, but we do observe
		\begin{itemize}
			\item The choice
			\item Data about the alternatives
			\item Data about the decision makers
		\end{itemize}
		\item We model the utility of alternative $j$ as $U_{nj} = V_{nj} + \varepsilon_{nj}$
		\begin{itemize}
			\item $V_{nj}$ is the component of utility from observed factors
			\item $\varepsilon_{nj}$ is the component of utility we do not observe
		\end{itemize}
		\item We do not observe $\varepsilon_{nj}$, so we cannot model the choice with certainty, but we can treat $\varepsilon_{nj}$ as random and form probabilities
	\end{itemize}
\end{frame}

\begin{frame}\frametitle{Representative Utility Example}
    Let's write down the representative utility for each of the four commute options from problem 3(a) on problem set 1
    \begin{itemize}
    	\item Intercept term for all but one alternative
    	\item Cost divided by income with a common coefficient
    	\item Time with alternative-specific coefficients
    \end{itemize}
    \begin{alignat*}{5}
    	&V_{nk} &&= &&\beta_1 \frac{C_{nk}}{I_n} + \beta_2 T_{nk} \qquad \qquad && U_{nk} &&= V_{nk} + \varepsilon_{nk} \\
    	&V_{nb} &&= \alpha_b + &&\beta_1 \frac{C_{nb}}{I_n} + \beta_3 T_{nb} \qquad \qquad && U_{nb} &&= V_{nb} + \varepsilon_{nb} \\
    	&V_{nc} &&= \alpha_c + &&\beta_1 \frac{C_{nc}}{I_n} + \beta_4 T_{nc} \qquad \qquad && U_{nc} &&= V_{nc} + \varepsilon_{nc} \\
    	&V_{nw} &&= \alpha_w + &&\beta_1 \frac{C_{nw}}{I_n} + \beta_5 T_{nw} \qquad \qquad && U_{nw} &&= V_{nw} + \varepsilon_{nw} 
    \end{alignat*}
\end{frame}

\begin{frame}\frametitle{Choice Probabilities}
	The decision maker chooses the alternative that gives the greatest utility
	\begin{itemize}
		\item Decision maker $n$ chooses alternative $i$ if and only if $U_{ni} > U_{nj} \; \forall j \neq i$
		\item But we treat $\varepsilon_{nj}$ as random, so we model the probability that a given alternative is chosen
	\end{itemize}
	\vspace{2ex}
    The probability that decision maker $n$ chooses alternative $i$ is
    \begin{align*}
    	P_{ni} &= \Pr(U_{ni} > U_{nj} \; \forall j \neq i) \\
    	&= \int_\varepsilon I(\varepsilon_{nj} - \varepsilon_{ni} < V_{ni} - V_{nj} \; \forall j \neq i) f(\varepsilon_n) d\varepsilon_n
    \end{align*} \\
    \vspace{2ex}
    We make assumptions about the joint density of unobserved components, $f(\varepsilon_n)$, to make this integral more tractable
    \begin{itemize}
    	\item Different assumptions about $f(\varepsilon_n)$ yield different discrete choice models
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Choice Probabilities Example}
    The probability that decision maker $n$ chooses to drive a car to campus is
    \begin{align*}
    	P_{nc} &= \Pr(U_{nc} > U_{nk}, U_{nc} > U_{nb}, U_{nc} > U_{nw}) \\
    	&= \int_{\varepsilon} I(\varepsilon_{nk} - \varepsilon_{nc} < V_{nc} - V_{nk}, \\
    	& \qquad \quad \varepsilon_{nb} - \varepsilon_{nc} < V_{nc} - V_{nb}, \\
    	& \qquad \quad \varepsilon_{nw} - \varepsilon_{nc} < V_{nc} - V_{nw}) f(\varepsilon_n) d\varepsilon_n
    \end{align*}
    Choice probabilities for the other three alternatives are defined similarly
\end{frame}

\begin{frame}\frametitle{Logit Model}
    Logit assumption about the joint distribution of unobserved utility
	$$\varepsilon_{nj} \sim \text{i.i.d.\ type I extreme value (Gumbel) with } Var(\varepsilon_{nj}) = \frac{\pi^2}{6}$$ \\
	\vspace{2ex}
	Logit choice probabilities have a closed-form expression
	$$P_{ni} = \frac{e^{V_{ni}}}{\sum_j e^{V_{nj}}}$$
\end{frame}

\begin{frame}\frametitle{Logit Choice Probabilities Example}
    The logit choice probability for each commute mode is
    \begin{alignat*}{2}
    	P_{nk} &= \frac{e^{V_{nk}}}{\sum_j e^{V_{nj}}} &&= \frac{e^{\beta_1 \frac{C_{nk}}{I_n} + \beta_2 T_{nk}}}{e^{V_{nk}} + e^{V_{nb}} + e^{V_{nc}} + e^{V_{nw}}} \\
    	P_{nb} &= \frac{e^{V_{nb}}}{\sum_j e^{V_{nj}}} &&= \frac{e^{\alpha_b + \beta_1 \frac{C_{nb}}{I_n} + \beta_3 T_{nb}}}{e^{V_{nk}} + e^{V_{nb}} + e^{V_{nc}} + e^{V_{nw}}} \\
    	P_{nc} &= \frac{e^{V_{nc}}}{\sum_j e^{V_{nj}}} &&= \frac{e^{\alpha_c + \beta_1 \frac{C_{nc}}{I_n} + \beta_4 T_{nc}}}{e^{V_{nk}} + e^{V_{nb}} + e^{V_{nc}} + e^{V_{nw}}} \\
    	P_{nw} &= \frac{e^{V_{nw}}}{\sum_j e^{V_{nj}}} &&= \frac{e^{\alpha_w + \beta_1 \frac{C_{nw}}{I_n} + \beta_5 T_{nw}}}{e^{V_{nk}} + e^{V_{nb}} + e^{V_{nc}} + e^{V_{nw}}}
    \end{alignat*}
\end{frame}

\begin{frame}\frametitle{Estimating the Logit Model}
    We estimate the logit model by finding the set of parameters that best fit our data
    \begin{itemize}
    	\item Parameters: $\alpha_b$, $\alpha_c$, $\alpha_w$, $\beta_1$, $\beta_2$, $\beta_3$, $\beta_4$, and $\beta_5$
    	\item What set of parameters makes it most likely to observe the data that we do observe?
    \end{itemize}
    \vspace{3ex}
    Two options for estimation
    \begin{enumerate}
    	\item Code up the maximum likelihood estimator...next time!
    	\item Let \texttt{mlogit()} find the MLE for us
    \end{enumerate}
\end{frame}

\begin{frame}\frametitle{\texttt{mlogit()} in R}
    Two steps to estimating a multinomial logit model in R with \texttt{mlogit()}
    \begin{enumerate}
    	\item Use \texttt{mlogit.data()} to organize your dataset in a way that \texttt{mlogit()} will understand
    	\begin{itemize}
    		\item See previous R code examples for how to do this
    		\item Not trivial, but once you get it figured out, not too hard
    	\end{itemize}
    	\item Use \texttt{mlogit()} to estimate model parameters
    	\begin{itemize}
    		\item Tricky part is specifying the model formula correctly
    	\end{itemize}
    \end{enumerate}
    \vspace{2ex}
    \texttt{mlogit(formula = y $\sim$ a | b | c)}
    \begin{itemize}
    	\item \texttt{a}: Variables with common coefficients
    	\item \texttt{b}: Individual-specific variables with alternative-specific coefficients
    	\item \texttt{c}: Alternative-specific variables with alternative-specific coefficients
    \end{itemize}
    \vspace{2ex}
    \texttt{mlogit} (and other packages) have vignettes that can be very helpful
    \begin{itemize}
    	\item \href{https://cran.r-project.org/web/packages/mlogit/index.html}{\texttt{cran.r-project.org/web/packages/mlogit/index.html}}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]\frametitle{\texttt{mlogit()} Example in R}
    We want to specify a model where the representative utility is
    $$V_{nj} = \alpha_j + \beta_1 \frac{C_{nj}}{I_n} + \beta_j T_{nj}$$ \\
    \vspace{2ex}
    \texttt{mlogit(formula = y $\sim$ a | b | c)}
    \begin{itemize}
    	\item \texttt{a}: Variables with common coefficients
    	\item \texttt{b}: Individual-specific variables with alternative-specific coefficients
    	\item \texttt{c}: Alternative-specific variables with alternative-specific coefficients
    \end{itemize}
    \vspace{2ex}
    <<include = FALSE>>=
    ### Load and look at dataset
    ## Load tidyverse and mlogit
    library(tidyverse)
    library(mlogit)
    ## Load dataset
    data_multi <- read_csv('travel_multinomial.csv')
    ## Look at dataset
    data_multi
    @
    <<include = FALSE>>=
    ### Estimate multinomial logit model using mlogit
    ## Convert dataset to mlogit format
    data_mlogit <- data_multi %>% 
      mlogit.data(shape = 'wide', choice = 'mode', varying = 2:9, sep = '_')
    @
    <<>>=
    ## Model choice as multinomial logit with common cost/income coefficient,
    ## alternative intercepts, and alternative-specific time coefficients
    model_mlogit <- data_mlogit %>% 
      mlogit(mode ~ I(cost / income) | 1 | time, data = .)
    @
\end{frame}

\begin{frame}[fragile]\frametitle{\texttt{mlogit()} Results in R}
    \vspace{1ex}
    <<size = 'tiny'>>=
    ## Summarize model results
    model_mlogit %>% 
      summary()
    @
\end{frame}

\begin{frame}\frametitle{Counterfactual Simulations}
    One of the most powerful aspects of structural estimation (including the logit model) is that we recover structural parameters that describe choices, behaviors, preferences, etc. \\
    \vspace{2ex}
    We can use these structural parameters to conduct ``counterfactual simulations''
    \begin{itemize}
        \item How would outcomes change if in a simulated counterfactual scenario with different data but the same structural parameters?
    \end{itemize}
    \vspace{2ex}
    Examples
    \begin{itemize}
        \item How would a higher minimum wage affect employment outcomes?
        \item How much additional rooftop solar energy would be generated by larger federal subsidies?
        \item How would firm competition, entry, and exit change under stricter regulations?
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Counterfactual Simulation Example}
    How many additional graduate students would take the bus if it was faster? Or if it was cheaper? \\
    \vspace{1ex}
    Steps to answer this question
    \begin{enumerate}
        \item Create a new dataset that represents the new ``counterfactual'' setting
        \item Combine the same parameter estimates (from two slides ago) with the new data to calculate the counterfactual utility for each alternative
        \item Use the counterfactual utilities to calculate counterfactual choice probabilities
        \item Calculate how many graduates students are estimated to take the bus
        \begin{itemize}
            \item Assign each student to the alternative with the greatest choice probability (or greatest utility)
            \item Or add up choice probabilities to get an expectation of the number of bus riders
        \end{itemize}
    \end{enumerate}
    \vspace{1ex}
    Even though you observe real outcomes, you should also do this for the original data, so you have a fair comparison for your counterfactual
\end{frame}

\begin{frame}\frametitle{Announcements}
    Reading for next time
    \begin{itemize}
        \item Train textbook, Chapters 3.7--3.8
        \item Bayer et al. (2009)
    \end{itemize}
    \vspace{3ex}
    Upcoming
    \begin{itemize}
        \item Problem Set 2 will be posted soon, due October 17
    \end{itemize}
\end{frame}

\end{document}
